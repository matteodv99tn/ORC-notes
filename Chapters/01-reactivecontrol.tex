% !TEX root =  ../notes.tex
\chapter{Reactive Controls}
	Usually while dealing with manipulators (or robot in generals) we are interested in controlling their \textit{dynamics}, so affecting the system's behavior. Let us call $q \in \mathds R^n$ the \textit{Lagrangian coordinates} that are used to describe the system configuration, and denote with $\dot q \in \mathds R^n$ their velocity. The dynamic of the system is then described by the following nonlinear differential equation:
	\begin{equation} \label{eq:temp:1}
		M(q) \ddot q + C(q,\dot q) \dot q + g(q) = \tau + J(q)^\top w
	\end{equation}
	where $M\in \mathds R^{n\times n}$ is the symmetric positive-definite \textit{mass-matrix}, $C \in \mathds R^{n\times n}$ is a matrix that takes into account both centrifugal and Coriolis force, while $g \in \mathds R^n$ accounts for gravity; $\tau \in \mathds R^n$ contains the joint torques.
	If the robot is in contact with the environment (suppose, without loss of generality, that the contact is at the end-effector), the dynamics also features the term $w \in \mathds R^6$, which is the contact \textit{wrench} (composed by a 3D force and a 3D moment), which is projected in joint space using the end-effector Jacobian $J \in \mathds R^{6 \times n}$. 
	Often the terms $C$ and $g$ are condensed in the so-called \textit{bias forces} $h \in \mathds R^n$, rewriting \eqref{eq:temp:1} as:
	\begin{equation} \label{eq:dynamic}
		M(q) \ddot q + h(q,\dot q) = \tau + J(q)^\top w
	\end{equation}

	Note that, in general, $M, h$ and $J$ are nonlinear functions of the state $(q,\dot q)$, so linear control theory cannot be applied to control this class of dynamical systems. 
	Nonetheless, \eqref{eq:dynamic} is linear with respect to $\ddot q$ and $\tau$ (once $q,\dot q$ and $w$ are fixed), which is an important property that can be exploited for its control.
	
\section{Joint-Space Motion Control}
	The trajectory-tracking \textit{control} problem addresses the question of finding the control inputs $\tau$ that make the system follow a reference trajectory. 
	Denoted with $q^{ref}(t)$ the \textit{reference joint trajectory}, the control problem can be loosely defined as:
	\[ \textrm{find } \tau(t) \qquad \textrm{such that } q(t) \simeq q^{ref}(t) \]
	
	\paragraph{PID control} The simplest strategy that we can use to solve this problem is by means of a \textit{Proportional Integrative Derivative} (\textit{PID}) controller:
	\begin{equation} \label{eq:PIDforce}
		\tau(t) = K_p e(t) + K_d \dot e(t) + K_i\int_0^t e(\zeta)\, d\zeta
	\end{equation}
	where $e(t) = q^{ref}(t) - q(t)$ is the \textit{error} between the reference trajectory and the real measured coordinates, and $K_p,K_d,K_i \in \mathds R^{n\times n}$ are respectively the \textit{proportional}, \textit{derivative} and \textit{integral gain matrices}, which must be positive-definite to ensure stability.
	
	As a rule of thumb, such feedback gains are tuned by first setting the proportional gain, following the derivative one, and last the integral part. In general the best tracking performance is achieved by increasing the proportional gain $K_p$: this however leads to a \textit{stiff} system that is usually less safe for human interaction (since high forces are exerted by the robot itself). For this reason more advanced techniques are used to solve the control problem in joint coordinate.
		
	\paragraph{Inverse-dynamics control} Assumed that the system is known and deterministic (hypothesis carried out throughout most of the course), then both $M$ and $h$ in \eqref{eq:dynamic} are known, and can be exploited to improve the control performance. In inverse-dynamics control (also known as \textit{feedback linearization} or \textit{computed torques}), the controller computes a desired acceleration $\ddot q^d$ for the joint coordinates, and the torques are then computed by exploiting the system dynamics \eqref{eq:dynamic}:
	\begin{equation} \label{eq:inversedynamiccontrol}
	\begin{cases}
		\tau & = M \ddot q^d + h \\ 
		\ddot q^d &= \ddot q^{ref} + K_d \dot e + K_p e
	\end{cases}
	\end{equation}
	Using the control law \eqref{eq:inversedynamiccontrol}, the closed-loop dynamics becomes:
	\begin{align*}
		M \ddot q + h & = \tau \\ 
		M \ddot q + h & = M\ddot q^d + h \\
		\ddot q & = \ddot q^d = \ddot q^{ref} + K_d\dot e + K_p e \\
		0 & = \ddot e + K_d\dot e + K_p e
	\end{align*}
	At this point the stability of the system can be analyzed with linear techniques by transforming this differential equation to first order; defining the vector $y = (e,\dot e) \in \mathds R^{2n}$, the system reduces to the following linear dynamics:
	\[ \dot y = A y \qquad \textrm{with } A  = \begin{bmatrix}
		0 & I \\ -K_p & -K_d
	\end{bmatrix}\]
	Linear theory provides us ways to tune $K_p, K_d$ in such a way that the overall matrix be stable (by enforcing that all eigenvalues of $A$ have a negative real part).
	
	Controller \eqref{eq:inversedynamiccontrol} usually leads to less stiff systems (which is typically desirable), but a very accurate model of the systems dynamics is required, i.e. \eqref{eq:dynamic} must be known.
	
	\paragraph{Integral gain} In \eqref{eq:PIDforce} it has been necessary to embed an integral term in the control law to compensate for the effect of gravity (since no system knowledge is required): this effect is nonlinear in the robots configuration and the integral gain aims to compensate such contribution asymptotically.\\
	In \eqref{eq:inversedynamiccontrol} the integral term is instead missing since all gravitational actions are modeled by the bias force $h$, thus it is automatically compensated by the computed torques law ($\ddot q^d$ must depend just on the tracking error and need not compensate for gravity).
	
	
\section{Cartesian-Space Motion Control}	
	Defining the desired behavior of the robot in joint coordinates is typically hard. A much easier way to define it is in terms of Cartesian space motion of the end-effector. Therefore, it is interesting to have control strategies that work directly in Cartesian space. A simple way to achieve this is to transform the reference Cartesian-space trajectory $x^{ref}(t)$ in a reference joint-space trajectory $q^{ref}(t)$ by solving the so-called \emph{inverse-geometry} problem. This problem consists in finding a valid joint configuration $q$ such that the end-effector position (and possibly orientation) matches a desired value. 
	This solution can theoretically work, but it presents several downsides. First, we have to deal with the high nonlinearity of the geometry function, which makes it impossible to find an analytical solution of the problem, even for simple robots. This is particularly important if the reference trajectory cannot be known in advance (e.g., if the end-effector has to track a moving object), and therefore the inverse-geometry problem must be solved inside the control loop.
	
	We can therefore try to design a control law that works directly with a Cartesian-space reference trajectory $x^{ref}(t)$. We want to compute the joint torques $\tau(t)$ such that the end-effector trajectory $x(t) \in \mathds R^3$ (in Cartesian coordinates) follows $x^{ref}(t)$:
	\[ x(t) \simeq x^{ref}(t) \]
	
	\paragraph{Operational-Space Control} Let us start by defining the relationship between the end-effector position $x \in \mathds{R}^3$ and the joint configuration $q$, which is the so-called \emph{forward geometry} function:
	\begin{equation}
	x = \text{FG}(q)
	\end{equation}
	By taking the time derivative of this relationship we get:
	\begin{equation}
	\dot x = \frac{d}{dt} \text{FG}(q) = \frac{d \text{FG}(q)}{dq} \frac{dq}{dt} = J(q) \dot q
	\end{equation}
	Taking the time derivative once again:
	\begin{equation}
	\ddot x = J(q) \ddot q + \dot{J}(q, \dot q) \dot q
	\end{equation}
	This relationship between $\ddot x$ and $\ddot q$ will be useful in the following derivation.
	Let us pre-multiplying the systems dynamic \eqref{eq:dynamic} by $JM^{-1}$, to map the equation from joint to Cartesian space:
	\begin{equation} \label{eq:temp:2}
	\begin{split}
		J\cancel{M^{-1}M}\ddot q + JM^{-1} h & = JM^{-1} \tau \\
		\ddot x - \dot J \dot q + JM^{-1}h & =
	\end{split}
	\end{equation}
	where $J \ddot q$ has been substituted by $\ddot x - \dot J \dot q$. 
	Assuming that the Jacobian $J$ is full-row rank (i.e. the end-effector is allowed to move in all directions) then $JM^{-1}J^\top \in \mathds R^{3 \times 3}$ is invertible; pre-multiplying \eqref{eq:temp:2} by the matrix $\Lambda \triangleq \big(JM^{-1}J^\top\big)^{-1}$ gives
	\begin{equation*}
		\Lambda \ddot x + \underbrace{\Lambda\big(JM^{-1}h - \dot J \dot q\big)}_{\mu} = \Lambda J M^{-1}\tau
	\end{equation*}
	
	As a final step to get our Cartesian-space dynamics, we can assume that the joint torques $\tau$ are generated by a virtual force $f_\tau \in \mathds R^3$ applied at the end-effector; in this way we have that $\tau = J^\top f_\tau$, and the previous equation becomes:
	\begin{equation} \label{eq:temp:3}
	\begin{split}
		\Lambda \ddot x + \mu & = \Lambda J M^{-1} J^\top f_\tau = \big(JM^{-1}J^\top\big)^{-1} J M^{-1} J^\top f_\tau \\ 
		\Lambda \ddot x + \mu & = f_\tau
	\end{split}
	\end{equation}
	Now that we have a Cartesian-space version of the robot dynamics, in the same spirit as the inverse-dynamics control discussed above, we can design a Cartesian-space inverse dynamics controller (a.k.a. Operational-Space Control):
	\begin{equation} \label{eq:cartesiancontroller}
	\begin{cases}
		\tau & = J^\top f_\tau \\
		f_\tau & = \Lambda \ddot x^d + \mu \\
		\ddot x^d & = \ddot x^{ref} + K_d\big(\dot x^{ref} - \dot x\big) + K_p\big(x^{ref} - x\big)
	\end{cases}
	\end{equation}
	A simplified version of this controller can be obtained by compensating for bias forces directly in joint space, rather than in Cartesian space:
	\begin{equation} \label{eq:cartesiancontroller_simp}
	\begin{cases}
		\tau & = J^\top f_\tau \textcolor{red}{+ h}\\
		f_\tau & = \Lambda \ddot x^d
	\end{cases}
	\end{equation}
	To prove the effectiveness of the controller \eqref{eq:cartesiancontroller_simp} we can compute the closed-loop dynamics:
	\begin{align*}
		JM^{-1} \Big( M \ddot q + h & = \tau = J^\top \Lambda \ddot x^d + h \Big) \\
		J \ddot q + JM^{-1} h & = JM^{-1}J^\top \Lambda \  \ddot x^d + JM^{-1} h \\
		J \ddot q & = \ddot x^d \\
		\ddot x - \dot J \dot q & = \ddot x^d
	\end{align*}
	As long as the systems does not move too fast, the term $\dot J \dot q$ is negligible and the end-effectors acceleration $\ddot x$ matches the desired one $\ddot x^d$.
	
	\paragraph{Redundancy resolution} Controller \eqref{eq:cartesiancontroller} aims just to control the 3D motion of the end-effector; however, the number of actuated joints $n$ typically exceeds the 3 degrees of freedom of the end-effector, therefore there are theoretically infinitely many joint configurations that allow to achieve the same end-effector position. The suggested control tracks the desired end-effector position, but it might happen over time that the system reaches \textit{singular configurations} for which $J$ is no longer full-row rank (losing the capability to move in some directions): in this case $JM^{-1}J^\top$ is no longer invertible and the control law cannot be computed.
	
	\textit{Redundancy resolution} aims to solve this problem: since there are infinitely many configurations that allow to achieve a desired $x$, the idea is now to find some additional joint torques that do not impact the end-effector motion, but helps avoiding singular configurations.
	
	Observed that $\Lambda JM^{-1} = \big(JM^{-1}J^\top\big)^{-1}JM^{-1}$ is a \textit{left-inverse} of $J^\top$, i.e. 
	\[ \textrm{let } \big(JM^{-1}J^\top\big)^{-1}JM^{-1} = {J^\top}^\dagger \qquad \textrm{then } {J^\top}^\dagger J^\top = I \]
	Note that in general $J^\top {J^\top}^\dagger \neq I$.
	
	If we now consider any torque $\tau_0$ in the kernel of ${J^\top}^\dagger$ it happens that the dynamics of the system in Cartesian space is not affected at all; recalling \eqref{eq:temp:3} we have that:
	\[ \Lambda \ddot x + \mu = {J^\top}^\dagger\big(\tau + \tau_0\big) = {J^\top}^\dagger \tau \qquad \forall \tau_0 \in \ker\{{J^\top}^\dagger\} \]
	Computing $\tau_0$ can be hard since there is no upfront guarantee that the motion will avoid singular configuration, however we can compute such torques as
	\[ \tau_0 = \big(I - J^\top {J^\top}^\dagger \big) \tau_1 \qquad \forall \tau_1 \in \mathds R^n \]
	Such choice always lies in $\ker\{{J^\top}^\dagger\}$, in fact
	\begin{align*}
		{J^\top}^\dagger \tau_0 & = {J^\top}^\dagger \big(I - J^\top {J^\top}^\dagger\big) \tau_1 \\
		& = \big({J^\top}^\dagger - {J^\top}^\dagger J^\top {J^\top}^\dagger\big) \tau_1 \\
		& = \big({J^\top}^\dagger - {J^\top}^\dagger\big) \tau_1 = 0 \hspace{2cm} \forall \tau_1 \in \mathds R^n
	\end{align*}

	With this premise we can improve controller \eqref{eq:cartesiancontroller} by adding an extra term $\tau_0$ that tries to maintain the joint configuration as close as possible to a reference configuration $q^{ref}$, in order to avoid singular configurations:
	\begin{equation} \label{eq:cartesiancontrollerimproved}
	\begin{cases}
		\tau & = J^\top f_\tau +  \big(I - J^\top {J^\top}^\dagger\big) \tau_1\\
		f_\tau & = \Lambda \ddot x^d + \mu \\
		\ddot x^d & = \ddot x^{ref} + K_d\big(\dot x^{ref} - \dot x\big) + K_p\big(x^{ref} - x\big) \\
		\tau_1 & = M\big(K_{p1}(q^{ref} - q) - K_{d1}\dot q\big) + h
	\end{cases}
	\end{equation}
	 
	
\section{Impedance control}
	Controllers \eqref{eq:cartesiancontroller} and \eqref{eq:cartesiancontrollerimproved} allow to control the robot directly in Cartesian coordinates; such techniques require a very accurate knowledge of the system of interest to work properly.\\
	Model inaccuracies can be compensated to a certain extent by increasing the controller gains, improving the tracking capability; however, this solution can lead to an unsafe stiff system, since in case of contact the controller might generate high forces, which could brake either the robot or the environment.
	
	To overcome this limitation we can use \textit{interaction control}, particularly useful to model contact of the end-effector with the surrounding environment. The underlying idea is that if we have access to an estimate of the contact force, then we can regulate the motion accordingly. Based on this simple idea, there are two main categories of controllers.
	\textit{Direct force controllers} mainly focus on controlling the applied contact forces (not covered in this course).
	\textit{Indirect force controllers} try to enforce a certain dynamic relationship between force and position. This method is also known as \textit{impedance control}.
	
	In impedance control (in Cartesian space) we want the end-effector to behave as a mass-spring-damper subject to an external contact force $f$:
	\begin{equation} \label{eq:spring}
		M_d \ddot x + B \dot x + K x = f
	\end{equation}
	where $M_d, B, K$ are matrices defining the desired mass, damping and stiffness.
	
	Once the contact model \eqref{eq:spring} is defined, the controller needs to compute at each time instant the joint torques $\tau$ to follow the desired behavior. 
	Starting from \eqref{eq:temp:3}, the dynamics projected in Cartesian space is simply 
	$$
	\Lambda \ddot x + \mu = {J^\top}^\dagger \tau + f
	$$
	Solving explicitly \eqref{eq:spring} for the acceleration provides the desired value 
	$$
	\ddot x^d = M_d^{-1}\big(f-B\dot x - Kx\big),
	$$ 
	which substituted in the dynamics:
	\[ \Lambda M_d^{-1}\big(f - B\dot x - K x\big) + \mu = {J^\top}^\dagger \tau + f \]
	As we did for the Operational-Space Control, assuming the joint torques $\tau$ are generated by a virtual end-effector force $f_\tau$, then the previous equation can be solved for $f_\tau$ as:
	\begin{align*}
		f_\tau & = \Lambda M_d ^{-1} \big( f - B\dot x - Kx \big) + \mu - f \\
		& = -\Lambda M_d^{-1}\big(B\dot x + K x\big) + \mu + \big(\Lambda M_d^{-1} - I\big) f
	\end{align*}
	At this point in order to compute $\tau$ (from $f_\tau$) it's required an estimate of the contact force $f$ that, unfortunately, usually comes from very noisy sensors and with time delays that might lead to unstable systems. A trick that we can use to overcome this limitation is to set $M_d = \Lambda$ in the desired dynamics \eqref{eq:spring}: with this choice, $f_\tau$ no longer depends on the contact force $f$ (since $\Lambda M_d^{-1} = I$). 
	At the end, the resulting control law simplifies to:
	\begin{equation}
		\tau = J^\top f_\tau = J^\top \big(-Kx - B\dot x + \mu\big)
	\end{equation}
	Similar derivations can be carried out even for cases where a reference trajectory and a reference contact force have to be tracked, by simply modifying the desired dynamics in this way:
	\begin{equation} \label{eq:spring}
		M_d (\ddot x^{ref} - \ddot x) + B (\dot x^{ref} - \dot x) + K (x^{ref} - x) = f^{ref} - f
	\end{equation}
	
\section{QP-based reactive control}
	Up to now only simple controllers have been presented, which do not rely on optimality conditions. In this section we turn our attention to \textit{optimization-based approaches} that exploit numerical optimization solvers to determine the optimal control inputs subject to constraints (such as actuator effort, joint position and velocity limits), which until now it was not possible to consider.
	
\subsection{Joint-space control}
	To track a reference trajectory in joint space $q^{ref}$, we have already discussed the inverse-dynamics controller \eqref{eq:inversedynamiccontrol}, which is:
	\[ \tau = M \ddot q^d + h \qquad\textrm{with } \ddot q^d = \ddot q^{ref} + K_d \dot e + K_p e \]
	%
	The same result can be achieved by solving the following \textit{optimization problem}:
	\begin{equation} \label{eq:qpocp}
	\begin{split}
		\min_{\tau, \ddot q}\quad & \frac 1 2 \big\|\ddot q - \ddot q^d \big\|^2 = \frac 1 2 \big(\ddot q - \ddot q^d\big)^\top \big(\ddot q - \ddot q^d\big) \\
		\textrm{sub. to:}\quad & M \ddot q + h = \tau
	\end{split}
	\end{equation}
	where $\frac 1 2 \big\|\ddot q - \ddot q^d \big\|^2$ is the \textit{cost function} that needs to be minimized with respect to the \textit{decision variables} $\ddot q, \tau$, while satisfying the \textit{constraint} $M\ddot q + h = \tau$ (i.e. the system dynamics).
	
	Since in \eqref{eq:qpocp} the cost is a squared norm, the minimum is obtained when the argument of the norm is zero, i.e. the optimal acceleration is $\ddot q^\star = \ddot q^d$; this implies that the optimal commanded torques are simply $\tau^\star = M \ddot q^d + h$, as in \eqref{eq:inversedynamiccontrol}.
	
	In this case the solution of the minimization problem was trivial, thus applying (\ref{eq:inversedynamiccontrol}) would have been easier, however the formulation (\ref{eq:qpocp}) leaves room for adding other constraints, which until now were impossible to consider. \\
	Problem \eqref{eq:qpocp} is usually referred to as a \textit{Quadratic Program} (\textit{QP}) since the cost is quadratic.
	
	\paragraph{Actuator effort bounds} Real actuators can't exert infinitely high forces, but their actions present a saturation limit that acts as a bound. Considering a symmetric behavior on the forces that can be generated, the actuator effort can be bounded as
	\[ -\tau^{max} \leq \tau \leq \tau^{max} \]
	
	Furthermore while dealing with electrical actuators, the motor drivers can handle just a limited amount of current, thus limiting the overall torque that can be generated.
	Since the motor current $i$ is proportional to the motor torque $\tau$, this limitation can be described by the following inequality constraint:
	\[ -i^{max} \leq \underbrace{K_i \tau}_{i} \leq i^{max} \]
	
	\paragraph{Joint velocity bounds} Motors and gears also have limited velocities $\dot q^{max}$. We observe that in \eqref{eq:qpocp} the joint velocity $\dot q$ is not a decision variable, but it is a constant because the control inputs cannot affect the current robot velocity. 
	Since we can't act on the current velocity, we can ensure that at the next time step the velocity doesn't exceed its limit. 
	Exploiting the Euler integration scheme, it holds that $\dot q(t + \Delta t) = \dot q(t) + \Delta t \, \ddot q$, thus a constraint that we might add to account for velocity limits is:
	\[ -\dot q^{max} \leq \dot q + \Delta t \, \ddot q \leq \dot q^{max} \]
	
	\paragraph{Joint position bounds} Actuators also have bounded joint positions, i.e. $q $ is constrained to lie in a interval $\big[q^{min}, q^{max}\big]$. 
	To satisfy such constraint we might be tempted to exploit the same trick used for the joint velocity limits, i.e. to compute $q$ at the next time-step by integrating $\ddot q$ twice, reaching a formulation of the form
	\[ q^{min} \leq q + \Delta t\, \dot q + \frac 1 2 \Delta t^2 \, \ddot q \leq q^{max} \tag{$\circ$}\]
	
	This solution would work if we only had joint position and velocity limits. 
	However, since in practice we also have joint acceleration limits (which are a direct consequence of the joint torque limits), this approach can lead to an \textit{unfeasible QP}.
	This is because in order not to exceed the joint position limits, the controller is required to produce a "high" acceleration $\ddot q$, which is incompatible with the actuator capabilities.
	
	A heuristic that can be used to mitigate this issue is by exploiting the same constraint ($\circ$), but using a larger value for the time-step $\Delta t$.
	This has the effect of "looking further into the future", and thus requiring the joint to decelerate more in advance.
	However, this can still lead to unfeasibility.
	An in-depth discussion of this issue can be found in the following paper~\cite{DelPreteRAL2018}, where an exact solution is suggested, under the assumption of constant joint acceleration bounds.
	
	
	\paragraph{QP problem} 
	The optimal control problem in \eqref{eq:qpocp} can be extended in order to embed all the bounds described so far, reaching the formulation:
	\begin{equation} \label{eq:qp}
		\begin{split}
			\min_{\tau, \ddot q}\quad & \frac 1 2 \big\|\ddot q - \ddot q^d \big\|^2 = \frac 1 2 \big(\ddot q - \ddot q^d\big)^\top \big(\ddot q - \ddot q^d\big) \\
			\textrm{sub. to:}\quad & M \ddot q + h = \tau \\
			& -\tau^{max} \leq \tau \leq \tau^{max} \\
			& -i^{max} \leq K_i \tau \leq i^{max} \\
			& -\dot q^{max} \leq \dot q + \Delta t \, \ddot q \leq \dot q^{max} \\
			& q^{min} \leq q + \Delta T\, \dot q + \frac 1 2 \Delta T^2 \, \ddot q \leq q^{max}
		\end{split}
	\end{equation}
	Such problem is harder to solve than \eqref{eq:qpocp} because its solution is usually non-trivial. 
	For this reason, \textit{QP solvers} are typically used, which are customized software to solve convex QP problems as~\eqref{eq:qpocp}.
	In the following, we quickly review some common forms of convex optimization problems and discuss how to solve them using free numerical solvers.
	
\subsection{Taxonomy of convex optimization problems} \label{sec:qp}
	In general not all optimization problems can be solved; moreover, for control purposes, the execution time of numerical algorithms is fundamental since we want to control the system with as little delay as possible.
	Optimization problems (\ref{eq:qpocp}) and (\ref{eq:qp}) are \textit{least-squares problems} (\textit{LSP}), which are a special subclass of convex optimization problems.
%	They are characterized by linear constraints (of the form $Ax\leq b$ or $Ax = b$) and a cost function that is a squared norm of an affine function, i.e. in the form $\|Ax + b\|^2$.
	
	\paragraph{Quadratic Programs}
	LSPs are a subclass of convex \textit{quadratic programs} (\textit{QPs}), which have linear constraints and a \textit{convex quadratic cost} in the form
	\begin{equation} \label{eq:qp_cost}
	\frac 1 2 x^\top H x + g^\top x
	\end{equation}
	with $H$ being a semi-positive definite matrix\footnote{A matrix $H$ is semi-positive definite if $x^T H x \ge 0 \quad \forall x$.}.
	
	Since there exist more numerical solvers for QPs than for LSPs, often LSPs are solved using QP solvers (still "ad hoc" solvers might find the solution more efficiently). 
	What is important for us, is that in general LSPs and QPs can be solved in low time with off-the-shelf softwares.
	
	\paragraph{Least-squares programs} 
	LSPs are characterized by a cost function of the form
	\begin{equation} \label{eq:lspfunction}
		f(x) = \frac 12 \big\|Ax - b\big\|^2 = \frac 1 2 \big(Ax-b\big)^\top\big(Ax -b\big) = \frac 1 2 x^\top A^\top A x - b^\top A x + \frac 1 2 b^\top b 
	\end{equation}
	We can notice that this cost is a special case of~\eqref{eq:qp_cost} because by setting $H = A^\top A$ (which by definition is semi-positive definite), and $g = -A^\top b$, we recover the cost of a general QP.
	
	Since the problem is convex then there is only one stationary point $x^\star$ of $f$, which is also the global minimum; $x^\star$ can be computed by setting to zero the gradient of the cost $f$, i.e. solving:
	\[ \nabla f = A^\top A x - A^\top b = 0 \]
	Assuming that $A^\top A$ is invertible the explicit solution of the minimizing argument is
	\begin{equation*} \tag{$\dagger$}
		x^\star = \big(A^\top A\big)^{-1} A^\top b
	\end{equation*}
	where $\big(A^\top A\big)^{-1} A^\top$ is the \textit{left pseudo-inverse} of $A$. If $A^\top A$ is not invertible but conversely $AA^\top$ is, then we can use the \textit{right pseudo-inverse} to obtain the solution
	\begin{equation*} \tag{$\ddagger$}
		x^\star = A^\top \big(AA^\top\big)^{-1} b
	\end{equation*}
	Plugging such optimal solution in (\ref{eq:lspfunction}) leads in fact to a zero (minimum) cost:
	\[ f(x^\star) =\big\| AA^\top\big(AA^\top\big)^{-1} b - b \big\|^2 = \|b-b\|^2 = 0 \]
	
	In general, the solution of least-squares minimization problem is determined by means of the \textit{Moore-Penrose pseudo-inverse $A^\dagger$} as
	\begin{equation} \label{eq:lspsol}
		x^\star = \arg \min_x \big\| Ax - b \big\|^2 = A^\dagger b
	\end{equation}
	where
	\begin{equation}
		A^\dagger = \begin{cases}
			A^\top\big(AA^\top\big)^{-1} & \textrm{if $A$ is full-row rank} \\
			\big(A^\top A\big)^{-1}A^\top & \textrm{if $A$ is full-column rank} 
		\end{cases}
	\end{equation}
	
	We observe now that both solutions have been obtained considering the respective definition of the Moore-Penrose pseudo-inverse based on the condition of the matrix $A$ (leading to the invertibility of $A^\top A$ or $A A^\top$). 
	Moreover, if $A$ is neither full-row and nor full-column rank, still $A^\dagger$ can be computed by means of the singular value decomposition, thus the optimal solution (\ref{eq:lspsol}) always exists for (\ref{eq:lspfunction}).
	
\subsection{Cartesian-Space Control}
	We can use quadratic programs also to solve control problems in Cartesian space. 
	Recalling the desired Cartesian acceleration $\ddot x^d = \ddot x^{ref} + K_p\big(x^{ref}-x\big) + K_d\big(\dot x^{ref} - \dot x\big)$ defined in (\ref{eq:cartesiancontroller}), we can formulate the control problem as:
	\begin{align*}
		\min_{\tau, \ddot q} \quad & \frac12 \big\|\ddot x - \ddot x^d\|^2 \\
		\textrm{sub. to:} \quad & M\ddot q + h = \tau
	\end{align*}
	The main issue with this formulation is that the cost function is independent of the \textit{decision variables} $\tau$ and $\ddot q$; in this case we must simply add a new constraint, relating $\ddot x$ with $\ddot q$, i.e. 
	\begin{equation}
	\begin{aligned}
		\min_{\tau, \ddot q, \ddot x} \quad & \frac12 \big\|\ddot x - \ddot x^d\|^2 \\
		\textrm{sub. to:} \quad & M\ddot q + h = \tau \\
		& \ddot x = J\ddot q + \dot J \dot q
	\end{aligned}
	\end{equation}
	To improve the numerical performance of the algorithm we can remove the last constraint and explicitly substitute it in the cost function:
	\begin{equation} \label{eq:qpcartesian}
		\begin{aligned}
			\min_{\tau, \ddot q} \quad & \frac12 \big\| J\ddot q + \dot J\dot q - \ddot x^d\|^2 \\
			\textrm{sub. to:} \quad & M\ddot q + h = \tau
		\end{aligned}
	\end{equation}
	Exploiting (\ref{eq:lspsol}) we can see that the optimal joint accelerations and torques are computed simply as
	\[ \ddot q^\star = J^\dagger \big(\ddot x^d - \dot J\dot q\big) \qquad \tau^\star = M \ddot q^\star + h \tag{$\triangle$} \]
	where in this case the coefficient $b$ is equal to $\ddot x^d - \dot J \dot q$ (all these quantities are constant in the problem).
	
%	\textbf{TODO: confrontare risultato con quello ottenuto in precedenza (pseudoinversa pesata)}
	
	
\subsection{Task-Space Control}
	In this section we generalize the concept of Cartesian-space control so that we can control not just the end-effector in Cartesian coordinates, but a \textit{task} (a.k.a. a \textit{control objective}) that the robot should achieve.
	
	Each task is usually described by an \textit{error function} $e(\cdot)$ that needs to be brought to zero; in all previous cases the error was just the difference between the current configuration and a reference one, i.e.
	\begin{equation}
		e(x,u,t) = y(x,u) - y^{ref}(t)
	\end{equation}
	where $x = (q,\dot q)$ is the \textit{state} of the system, and $u=\tau$ the inputs (using a more general notation).
	
	Since QP problems requires an error function $e$ that must be affine in the decision variable $\ddot q$, a transformation is required (such the one to solve the controls in cartesian space); minimizing directly $e$ is not possible as in general it depends only on $q$ and $\dot q$, not $\ddot q$ explicitly.\\
	To reach this goal we must impose the following two conditions on $e$ (or on it's derivative $\dot e,\ddot e$) for which:
	\begin{enumerate}
		\item $\lim_{t\rightarrow \infty} e(t) = 0$;
		\item the dynamics of $e$ is affine in the decision variables $\ddot q, u$.
	\end{enumerate}
	
	\paragraph{Velocity task function} Let's consider a case for which the error function depends just on the joint velocity (and eventually on time), so in the form $e(x,u,y) = e(\dot q, t) = y(\dot q) - y^{ref}(t)$; differentiating in time the error function provides
	\[ \dot e(\dot q, t) = \dot y - \dot y^{ref} = \pdiff y {\dot q} \diff {\dot q} t - \dot y^{ref} = J \ddot q - \dot y^{ref} \]
	This expression clearly satisfies the second requirement of being affine with respect to $\ddot q$; to ensure the second condition we can set $\dot e$ as proportional to the current error:
	\[ \dot e = -K_p e \]
	If $K_p$ is positive definite the linear dynamics is asymptotically stable, satisfying the second condition. The final cost function that can be used to solve this problem is so
	\begin{equation} 
	\begin{aligned} 
		J \ddot q - \dot y^{ref} & = - K_p e \qquad \textrm{with } K_p > 0 \\ 
		J\ddot q - \dot y^{ref} + K_p e & = 0
	\end{aligned}
	\end{equation}
	
	\paragraph{Position task function} Considering now a task depending just on the joint's position in the form $e(x,u,t) = e(q,t) = y(q) - y^{ref}(t)$, then an affine function in $\ddot q$ can be obtained considering 2 differentiation in time as follows:
	\[ \xrightarrow{\d/\d t} \qquad \dot e = J\dot q - \dot y^{ref} \qquad \xrightarrow{\d/\d t} \qquad \ddot e = J \ddot q + \dot J \dot q - \ddot y^{ref} \tag{$\circ$}  \]
	In this way the second requirement for $e$ is required. To study the first condition we need to reduce the dynamic to a first order exploiting the variable $z = (e,\dot e)$, and considering for this case a proportional-derivative controller the linear system boils down to
	\[ \dot z = \begin{pmatrix}
		\dot e \\ \ddot e
	\end{pmatrix} = \begin{bmatrix}
		0 & I \\ -K_p & - K_d
	\end{bmatrix} \begin{pmatrix}
		e \\ \dot e
	\end{pmatrix} = A z  \]
	In this case matrices $K_p,K_d > 0$ must be chosen in such a way that $\ddot e = -K_p e - K_d \dot e$ is asymptotically stable ($A$ musth be Hurwitz). Since now also the first condition is met, we can rewrite ($\circ$) as
	\begin{align*}
		J\ddot q + \dot J \dot q - \ddot y^{ref} & = - K_p e - K_d \dot e \\
		J\ddot q + \dot J \dot q + K_p e + K_d \dot e & = 0
	\end{align*}
	
	Linear theory suggests that such dynamic is exponentially stable, however in this case no constraints have been considered (but they can limit the actual stabilization performance).
	
	\paragraph{Input task function} The only way to build a task function $e(u, t)$ that depends just on the input torques $\tau = u$ is by ensuring that $e$ is actually affine in $u$ (that's a decision variable), i.e. must be of the form
	\[ e(u,t) = A(t) u - b(t) \]
	
	\paragraph{Task summary} As just presented we might have 3 main kind of task function, respectively:
	\begin{itemize}
		\item one that's affine in the input $\tau = u$;
		\item two that are non-linear functions of the states $x$ but for which an affine function of $\ddot q$ can be achieved by means of one or two differentiation in time for velocity and position tasks respectively.
	\end{itemize}
	In general a combination of multiple tasks can be collapsed to a single task exploiting an "augmented" state vector $z = (\ddot q, u)$ that determines the following affine function:
	\[ g(z) = \begin{bmatrix}
		A_x & A_u
	\end{bmatrix} \begin{pmatrix}
		\ddot q \\ u
	\end{pmatrix} - b = Az - b \]
	
	\paragraph{QP-based control} The \textit{task-space inverse dynamics} (\textit{TSID}), also referred as \textit{QP-based control}, solves optimization problems in the for
	\begin{equation}
	\begin{aligned}
		\min_{z =(\ddot q, \tau)} \quad & \big\|Az-b \big\|^2 \\
		\textrm{sub. to:} \quad & \begin{bmatrix}
			M & -I
		\end{bmatrix} z = -h \\ 
		& \textit{other constraints}
	\end{aligned}
	\end{equation}
	This is a generalization of the QP joint space control in (\ref{eq:qp}), choosing $A = \begin{bmatrix} I & 0 \end{bmatrix}$ and $b = \ddot q^d$, or the cartesian space control in (\ref{eq:qpcartesian}), choosing $A = \begin{bmatrix} J & 0 \end{bmatrix}$ and $b = \ddot x^d - \dot J \dot q$.
	
	\textbf{TODO: underactuated systems, rigid contacts, multi-task control}
	
 	
	
	