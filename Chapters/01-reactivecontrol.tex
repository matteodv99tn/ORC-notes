% !TEX root =  ../notes.tex
\chapter{Reactive Controls}
	Usually while dealing with manipulators (or robot in generals) we are interested in controlling their \textit{dynamics}, so affecting the system's behavior. Let us call $q \in \mathds R^n$ the \textit{Lagrangian coordinates} that are used to describe the system configuration, and denote with $\dot q \in \mathds R^n$ their velocity. The dynamic of the system is then described by the following nonlinear differential equation:
	\begin{equation} \label{eq:temp:1}
		M(q) \ddot q + C(q,\dot q) \dot q + g(q) = \tau + J(q)^\top w
	\end{equation}
	where $M\in \mathds R^{n\times n}$ is the symmetric positive-definite \textit{mass-matrix}, $C \in \mathds R^{n\times n}$ is a matrix that takes into account both centrifugal and Coriolis force, while $g \in \mathds R^n$ accounts for gravity; $\tau \in \mathds R^n$ contains the joint torques.
	If the robot is in contact with the environment (suppose, without loss of generality, that the contact is at the end-effector), the dynamics also features the term $w \in \mathds R^6$, which is the contact \textit{wrench} (composed by a 3D force and a 3D moment), which is projected in joint space using the end-effector Jacobian $J \in \mathds R^{6 \times n}$. 
	Often the terms $C$ and $g$ are condensed in the so-called \textit{bias forces} $h \in \mathds R^n$, rewriting \eqref{eq:temp:1} as:
	\begin{equation} \label{eq:dynamic}
		M(q) \ddot q + h(q,\dot q) = \tau + J(q)^\top w
	\end{equation}

	Note that, in general, $M, h$ and $J$ are nonlinear functions of the state $(q,\dot q)$, so linear control theory cannot be applied to control this class of dynamical systems. 
	Nonetheless, \eqref{eq:dynamic} is linear with respect to $\ddot q$ and $\tau$ (once $q,\dot q$ and $w$ are fixed), which is an important property that can be exploited for its control.
	
\section{Joint-Space Motion Control}
	The trajectory-tracking \textit{control} problem addresses the question of finding the control inputs $\tau$ that make the system follow a reference trajectory. 
	Denoted with $q^{ref}(t)$ the \textit{reference joint trajectory}, the control problem can be loosely defined as:
	\[ \textrm{find } \tau(t) \qquad \textrm{such that } q(t) \simeq q^{ref}(t) \]
	
	\paragraph{PID control} The simplest strategy that we can use to solve this problem is by means of a \textit{Proportional Integrative Derivative} (\textit{PID}) controller:
	\begin{equation} \label{eq:PIDforce}
		\tau(t) = K_p e(t) + K_d \dot e(t) + K_i\int_0^t e(\zeta)\, d\zeta
	\end{equation}
	where $e(t) = q^{ref}(t) - q(t)$ is the \textit{error} between the reference trajectory and the real measured coordinates, and $K_p,K_d,K_i \in \mathds R^{n\times n}$ are respectively the \textit{proportional}, \textit{derivative} and \textit{integral gain matrices}, which must be positive-definite to ensure stability.
	
	As a rule of thumb, such feedback gains are tuned by first setting the proportional gain, following the derivative one, and last the integral part. In general the best tracking performance is achieved by increasing the proportional gain $K_p$: this however leads to a \textit{stiff} system that is usually less safe for human interaction (since high forces are exerted by the robot itself). For this reason more advanced techniques are used to solve the control problem in joint coordinate.
		
	\paragraph{Inverse-dynamics control} Assumed that the system is known and deterministic (hypothesis carried out throughout most of the course), then both $M$ and $h$ in \eqref{eq:dynamic} are known, and can be exploited to improve the control performance. In inverse-dynamics control (also known as \textit{feedback linearization} or \textit{computed torques}), the controller computes a desired acceleration $\ddot q^d$ for the joint coordinates, and the torques are then computed by exploiting the system dynamics \eqref{eq:dynamic}:
	\begin{equation} \label{eq:inversedynamiccontrol}
	\begin{cases}
		\tau & = M \ddot q^d + h \\ 
		\ddot q^d &= \ddot q^{ref} + K_d \dot e + K_p e
	\end{cases}
	\end{equation}
	Using the control law \eqref{eq:inversedynamiccontrol}, the closed-loop dynamics becomes:
	\begin{align*}
		M \ddot q + h & = \tau \\ 
		M \ddot q + h & = M\ddot q^d + h \\
		\ddot q & = \ddot q^d = \ddot q^{ref} + K_d\dot e + K_p e \\
		0 & = \ddot e + K_d\dot e + K_p e
	\end{align*}
	At this point the stability of the system can be analyzed with linear techniques by transforming this differential equation to first order; defining the vector $y = (e,\dot e) \in \mathds R^{2n}$, the system reduces to the following linear dynamics:
	\[ \dot y = A y \qquad \textrm{with } A  = \begin{bmatrix}
		0 & I \\ -K_p & -K_d
	\end{bmatrix}\]
	Linear theory provides us ways to tune $K_p, K_d$ in such a way that the overall matrix be stable (by enforcing that all eigenvalues of $A$ have a negative real part).
	
	Controller \eqref{eq:inversedynamiccontrol} usually leads to less stiff systems (which is typically desirable), but a very accurate model of the systems dynamics is required, i.e. \eqref{eq:dynamic} must be known.
	
	\paragraph{Integral gain} In \eqref{eq:PIDforce} it has been necessary to embed an integral term in the control law to compensate for the effect of gravity (since no system knowledge is required): this effect is nonlinear in the robots configuration and the integral gain aims to compensate such contribution asymptotically.\\
	In \eqref{eq:inversedynamiccontrol} the integral term is instead missing since all gravitational actions are modeled by the bias force $h$, thus it is automatically compensated by the computed torques law ($\ddot q^d$ must depend just on the tracking error and need not compensate for gravity).
	
	
\section{Cartesian-Space Motion Control}	
	Defining the desired behavior of the robot in joint coordinates is typically hard. A much easier way to define it is in terms of Cartesian space motion of the end-effector. Therefore, it is interesting to have control strategies that work directly in Cartesian space. A simple way to achieve this is to transform the reference Cartesian-space trajectory $x^{ref}(t)$ in a reference joint-space trajectory $q^{ref}(t)$ by solving the so-called \emph{inverse-geometry} problem. This problem consists in finding a valid joint configuration $q$ such that the end-effector position (and possibly orientation) matches a desired value. 
	This solution can theoretically work, but it presents several downsides. First, we have to deal with the high nonlinearity of the geometry function, which makes it impossible to find an analytical solution of the problem, even for simple robots. This is particularly important if the reference trajectory cannot be known in advance (e.g., if the end-effector has to track a moving object), and therefore the inverse-geometry problem must be solved inside the control loop.
	
	We can therefore try to design a control law that works directly with a Cartesian-space reference trajectory $x^{ref}(t)$. We want to compute the joint torques $\tau(t)$ such that the end-effector trajectory $x(t) \in \mathds R^3$ (in Cartesian coordinates) follows $x^{ref}(t)$:
	\[ x(t) \simeq x^{ref}(t) \]
	
	\paragraph{Operational-Space Control} Let us start by defining the relationship between the end-effector position $x \in \mathds{R}^3$ and the joint configuration $q$, which is the so-called \emph{forward geometry} function:
	\begin{equation}
	x = \text{FG}(q)
	\end{equation}
	By taking the time derivative of this relationship we get:
	\begin{equation}
	\dot x = \frac{d}{dt} \text{FG}(q) = \frac{d \text{FG}(q)}{dq} \frac{dq}{dt} = J(q) \dot q
	\end{equation}
	Taking the time derivative once again:
	\begin{equation}
	\ddot x = J(q) \ddot q + \dot{J}(q, \dot q) \dot q
	\end{equation}
	This relationship between $\ddot x$ and $\ddot q$ will be useful in the following derivation.
	Let us pre-multiplying the systems dynamic \eqref{eq:dynamic} by $JM^{-1}$, to map the equation from joint to Cartesian space:
	\begin{equation} \label{eq:temp:2}
	\begin{split}
		J\cancel{M^{-1}M}\ddot q + JM^{-1} h & = JM^{-1} \tau \\
		\ddot x - \dot J \dot q + JM^{-1}h & =
	\end{split}
	\end{equation}
	where $J \ddot q$ has been substituted by $\ddot x - \dot J \dot q$. 
	Assuming that the Jacobian $J$ is full-row rank (i.e. the end-effector is allowed to move in all directions) then $JM^{-1}J^\top \in \mathds R^{3 \times 3}$ is invertible; pre-multiplying \eqref{eq:temp:2} by the matrix $\Lambda \triangleq \big(JM^{-1}J^\top\big)^{-1}$ gives
	\begin{equation*}
		\Lambda \ddot x + \underbrace{\Lambda\big(JM^{-1}h - \dot J \dot q\big)}_{\mu} = \Lambda J M^{-1}\tau
	\end{equation*}
	
	As a final step to get our Cartesian-space dynamics, we can assume that the joint torques $\tau$ are generated by a virtual force $f_\tau \in \mathds R^3$ applied at the end-effector; in this way we have that $\tau = J^\top f_\tau$, and the previous equation becomes:
	\begin{equation} \label{eq:temp:3}
	\begin{split}
		\Lambda \ddot x + \mu & = \Lambda J M^{-1} J^\top f_\tau = \big(JM^{-1}J^\top\big)^{-1} J M^{-1} J^\top f_\tau \\ 
		\Lambda \ddot x + \mu & = f_\tau
	\end{split}
	\end{equation}
	Now that we have a Cartesian-space version of the robot dynamics, in the same spirit as the inverse-dynamics control discussed above, we can design a Cartesian-space inverse dynamics controller (a.k.a. Operational-Space Control):
	\begin{equation} \label{eq:cartesiancontroller}
	\begin{cases}
		\tau & = J^\top f_\tau \\
		f_\tau & = \Lambda \ddot x^d + \mu \\
		\ddot x^d & = \ddot x^{ref} + K_d\big(\dot x^{ref} - \dot x\big) + K_p\big(x^{ref} - x\big)
	\end{cases}
	\end{equation}
	A simplified version of this controller can be obtained by compensating for bias forces directly in joint space, rather than in Cartesian space:
	\begin{equation} \label{eq:cartesiancontroller_simp}
	\begin{cases}
		\tau & = J^\top f_\tau \textcolor{red}{+ h}\\
		f_\tau & = \Lambda \ddot x^d
	\end{cases}
	\end{equation}
	To prove the effectiveness of the controller \eqref{eq:cartesiancontroller_simp} we can compute the closed-loop dynamics:
	\begin{align*}
		JM^{-1} \Big( M \ddot q + h & = \tau = J^\top \Lambda \ddot x^d + h \Big) \\
		J \ddot q + JM^{-1} h & = JM^{-1}J^\top \Lambda \  \ddot x^d + JM^{-1} h \\
		J \ddot q & = \ddot x^d \\
		\ddot x - \dot J \dot q & = \ddot x^d
	\end{align*}
	As long as the systems does not move too fast, the term $\dot J \dot q$ is negligible and the end-effectors acceleration $\ddot x$ matches the desired one $\ddot x^d$.
	
	\paragraph{Redundancy resolution} Controller \eqref{eq:cartesiancontroller} aims just to control the 3D motion of the end-effector; however, the number of actuated joints $n$ typically exceeds the 3 degrees of freedom of the end-effector, therefore there are theoretically infinitely many joint configurations that allow to achieve the same end-effector position. The suggested control tracks the desired end-effector position, but it might happen over time that the system reaches \textit{singular configurations} for which $J$ is no longer full-row rank (losing the capability to move in some directions): in this case $JM^{-1}J^\top$ is no longer invertible and the control law cannot be computed.
	
	\textit{Redundancy resolution} aims to solve this problem: since there are infinitely many configurations that allow to achieve a desired $x$, the idea is now to find some additional joint torques that do not impact the end-effector motion, but helps avoiding singular configurations.
	
	Observed that $\Lambda JM^{-1} = \big(JM^{-1}J^\top\big)^{-1}JM^{-1}$ is a \textit{left-inverse} of $J^\top$, i.e. 
	\[ \textrm{let } \big(JM^{-1}J^\top\big)^{-1}JM^{-1} = {J^\top}^\dagger \qquad \textrm{then } {J^\top}^\dagger J^\top = I \]
	Note that in general $J^\top {J^\top}^\dagger \neq I$.
	
	If we now consider any torque $\tau_0$ in the kernel of ${J^\top}^\dagger$ it happens that the dynamics of the system in Cartesian space is not affected at all; recalling \eqref{eq:temp:3} we have that:
	\[ \Lambda \ddot x + \mu = {J^\top}^\dagger\big(\tau + \tau_0\big) = {J^\top}^\dagger \tau \qquad \forall \tau_0 \in \ker\{{J^\top}^\dagger\} \]
	Computing $\tau_0$ can be hard since there is no upfront guarantee that the motion will avoid singular configuration, however we can compute such torques as
	\[ \tau_0 = \big(I - J^\top {J^\top}^\dagger \big) \tau_1 \qquad \forall \tau_1 \in \mathds R^n \]
	Such choice always lies in $\ker\{{J^\top}^\dagger\}$, in fact
	\begin{align*}
		{J^\top}^\dagger \tau_0 & = {J^\top}^\dagger \big(I - J^\top {J^\top}^\dagger\big) \tau_1 \\
		& = \big({J^\top}^\dagger - {J^\top}^\dagger J^\top {J^\top}^\dagger\big) \tau_1 \\
		& = \big({J^\top}^\dagger - {J^\top}^\dagger\big) \tau_1 = 0 \hspace{2cm} \forall \tau_1 \in \mathds R^n
	\end{align*}

	With this premise we can improve controller \eqref{eq:cartesiancontroller} by adding an extra term $\tau_0$ that tries to maintain the joint configuration as close as possible to a reference configuration $q^{ref}$, in order to avoid singular configurations:
	\begin{equation} \label{eq:cartesiancontrollerimproved}
	\begin{cases}
		\tau & = J^\top f_\tau +  \big(I - J^\top {J^\top}^\dagger\big) \tau_1\\
		f_\tau & = \Lambda \ddot x^d + \mu \\
		\ddot x^d & = \ddot x^{ref} + K_d\big(\dot x^{ref} - \dot x\big) + K_p\big(x^{ref} - x\big) \\
		\tau_1 & = M\big(K_{p1}(q^{ref} - q) - K_{d1}\dot q\big) + h
	\end{cases}
	\end{equation}
	 
	
\section{Impedance control}
	Controllers \eqref{eq:cartesiancontroller} and \eqref{eq:cartesiancontrollerimproved} allow to control the robot directly in Cartesian coordinates; such techniques require a very accurate knowledge of the system of interest to work properly.\\
	Model inaccuracies can be compensated to a certain extent by increasing the controller gains, improving the tracking capability; however, this solution can lead to an unsafe stiff system, since in case of contact the controller might generate high forces, which could brake either the robot or the environment.
	
	To overcome this limitation we can use \textit{interaction control}, particularly useful to model contact of the end-effector with the surrounding environment. The underlying idea is that if we have access to an estimate of the contact force, then we can regulate the motion accordingly. Based on this simple idea, there are two main categories of controllers.
	\textit{Direct force controllers} mainly focus on controlling the applied contact forces (not covered in this course).
	\textit{Indirect force controllers} try to enforce a certain dynamic relationship between force and position. This method is also known as \textit{impedance control}.
	
	In impedance control (in Cartesian space) we want the end-effector to behave as a mass-spring-damper subject to an external contact force $f$:
	\begin{equation} \label{eq:spring}
		M_d \ddot x + B \dot x + K x = f
	\end{equation}
	where $M_d, B, K$ are matrices defining the desired mass, damping and stiffness.
	
	Once the contact model \eqref{eq:spring} is defined, the controller needs to compute at each time instant the joint torques $\tau$ to follow the desired behavior. 
	Starting from \eqref{eq:temp:3}, the dynamics projected in Cartesian space is simply 
	$$
	\Lambda \ddot x + \mu = {J^\top}^\dagger \tau + f
	$$
	Solving explicitly \eqref{eq:spring} for the acceleration provides the desired value 
	$$
	\ddot x^d = M_d^{-1}\big(f-B\dot x - Kx\big),
	$$ 
	which substituted in the dynamics:
	\[ \Lambda M_d^{-1}\big(f - B\dot x - K x\big) + \mu = {J^\top}^\dagger \tau + f \]
	As we did for the Operational-Space Control, assuming the joint torques $\tau$ are generated by a virtual end-effector force $f_\tau$, then the previous equation can be solved for $f_\tau$ as:
	\begin{align*}
		f_\tau & = \Lambda M_d ^{-1} \big( f - B\dot x - Kx \big) + \mu - f \\
		& = -\Lambda M_d^{-1}\big(B\dot x + K x\big) + \mu + \big(\Lambda M_d^{-1} - I\big) f
	\end{align*}
	At this point in order to compute $\tau$ (from $f_\tau$) it's required an estimate of the contact force $f$ that, unfortunately, usually comes from very noisy sensors and with time delays that might lead to unstable systems. A trick that we can use to overcome this limitation is to set $M_d = \Lambda$ in the desired dynamics \eqref{eq:spring}: with this choice, $f_\tau$ no longer depends on the contact force $f$ (since $\Lambda M_d^{-1} = I$). 
	At the end, the resulting control law simplifies to:
	\begin{equation}
		\tau = J^\top f_\tau = J^\top \big(-Kx - B\dot x + \mu\big)
	\end{equation}
	Similar derivations can be carried out even for cases where a reference trajectory and a reference contact force have to be tracked, by simply modifying the desired dynamics in this way:
	\begin{equation} \label{eq:spring}
		M_d (\ddot x^{ref} - \ddot x) + B (\dot x^{ref} - \dot x) + K (x^{ref} - x) = f^{ref} - f
	\end{equation}
	
\section{QP-based reactive control}
	Up to now only simplest controller have been presented for which optimality condition have not been discussed. In this section we will focus more on \textit{optimization-based approaches} that exploits minimization to determine the optimal control solution with the addition of constraints (such actuator effort, joint position and velocity limits\dots) that until now it was not possible to consider.
	
\subsection{Joint space control}
	To control a desired trajectory in joint space (so given $q^{ref}$), controller (\ref{eq:inversedynamiccontrol}) has been proposed for which
	\[ \tau = M \ddot q^d + h \qquad\textrm{with } \ddot q^d = \ddot q^{ref} + K_d \dot e + K_p e \]
	
	The same result can be achieved by solving the following \textit{optimal control problem} (\textit{OCP}):
	\begin{equation} \label{eq:qpocp}
	\begin{split}
		\min_{\tau, \ddot q}\quad & \frac 1 2 \big\|\ddot q - \ddot q^d \big\|^2 = \frac 1 2 \big(\ddot q - \ddot q^d\big)^\top \big(\ddot q - \ddot q^d\big) \\
		\textrm{sub. to:}\quad & M \ddot q + h = \tau
	\end{split}
	\end{equation}
	where $\frac 1 2 \big\|\ddot q - \ddot q^d \big\|^2$ is the \textit{cost function} that needs to be minimized with respect to the \textit{minimization variables} $\ddot q, \tau$ and that must be subjected to the \textit{constraint} $M\ddot q + h = \tau$ (the dynamic law).
	
	Since in (\ref{eq:qpocp}) the cost is a quadratic function, the minimum is obtained by setting the argument of the norm to zero, i.e. the optimal acceleration is $\ddot q^\star = \ddot q^d$; this implies that the optimal commanded torque is simply $\tau^\star = M \ddot q^d + h$, as in (\ref{eq:inversedynamiccontrol}).
	
	In this case the solution of the minimization problem was trivial, thus applying (\ref{eq:inversedynamiccontrol}) would have been easier, however the formulation (\ref{eq:qpocp}) leaves room for adding other constraints that until were impossible to consider. \\
	Problem (\ref{eq:qpocp}) is usually referred as a \textit{quadratic program} (\textit{QP}) since the optimization problem has a quadratic cost.
	
	\paragraph{Actuator effort bounds} Real actuators can't exert infinitely high forces, but their actions present a saturation limit that acts as a bound. Considering a symmetric behavior on the forces that can be generated, the actuator effort can be bounded as
	\[ -\tau^{max} \leq \tau \leq \tau^{max} \]
	
	Furthermore while dealing with electrical actuators, the motor drivers can handle just a limited amount of current, thus limiting the overall torque that can be generated; this limitation can be described by the following inequality constraint:
	\[ -i^{max} \leq K_i \tau \leq i^{max} \]
	
	\paragraph{Joint velocity bounds} Actuators also present saturated joint velocities $\dot q^{max}$. We observe that in (\ref{eq:qpocp}) the joint velocity $\dot q$ is not a minimization argument, but is a value that's estimated by the robot itself. To bound the velocity we can use an integral constraint; since we can't act on the current velocity, we might minimize in a way that at the next time-step the velocity doesn't exceed the saturation limit. Exploiting the Euler approximation, it holds that $\dot q(t + \Delta t) = \dot q(t) + \Delta t \, \ddot q$, thus a constraint that we might add to take into account for velocities is
	\[ -\dot q^{max} \leq \dot q + \Delta t \, \ddot q \leq \dot q^{max} \]
	
	\paragraph{Joint position bounds} Actuators also have bounded joint position boundaries, i.e. $q $ is constrained to lie in a interval $\big[q^{min}, q^{max}\big]$. To satisfy such constraint we might be tempted to exploit the same trick used for the joint velocity saturation, by so computing $q$ at the next time-step by integrating $\ddot q$, reaching a formulation of the form
	\[ q^{min} \leq q + \Delta t\, \dot q + \frac 1 2 \Delta t^2 \, \ddot q \leq q^{max} \tag{$\circ$}\]
	
	Even if this solution theoretically works, in practice it leads to \textit{unfeasible QPs}: in order not to exceed the joint position saturation at high velocity, the controller is required to set a "high" acceleration $\ddot q$, conflicting with other boundaries set on the actuator efforts.
	
	A heuristic that can be used to overcome this limitation is by exploiting the same constraint ($\circ$), but using a wider time-step $\Delta t$ in order to "predict further in the future" the behavior of the system.
	
	\paragraph{QP problem} With the discussions said so far, the optimal control problem in (\ref{eq:qpocp}) can be extended in order to embed all bounds described so far, reaching the formulation
	\begin{equation} \label{eq:qp}
		\begin{split}
			\min_{\tau, \ddot q}\quad & \frac 1 2 \big\|\ddot q - \ddot q^d \big\|^2 = \frac 1 2 \big(\ddot q - \ddot q^d\big)^\top \big(\ddot q - \ddot q^d\big) \\
			\textrm{sub. to:}\quad & M \ddot q + h = \tau \\
			& -\tau^{max} \leq \tau \leq \tau^{max} \\
			& -i^{max} \leq K_i \tau \leq i^{max} \\
			& -\dot q^{max} \leq \dot q + \Delta t \, \ddot q \leq \dot q^{max} \\
			& q^{min} \leq q + \Delta T\, \dot q + \frac 1 2 \Delta T^2 \, \ddot q \leq q^{max}
		\end{split}
	\end{equation}
	Such OCP is is harder then (\ref{eq:qpocp}) and the solution is usually non-trivial, for this reason \textit{QP solvers} numerical methods have been developed. Since the cost is quadratic we can exploit \textit{convex optimization} that will be revised next.
	
\subsection{Review of convex optimization} \label{sec:qp}
	In general not all optimization problems have a solution; moreover for control purposes the execution time of numerical algorithms is fundamental since we want to control the system with less delay as possible.
	
	\paragraph{Taxonomy of convex optimization problems} Optimization problems (\ref{eq:qpocp}) and (\ref{eq:qp}) are particular minimization referred usually as \textit{least square problems} (\textit{LSP}) that are characterized by having linear constraint (of the form $Ax\leq b$ or $Ax = b$) and a cost function that is a squared norm of a linear function, i.e. in the form $\|Ax + b\|^2$.
	
	LSPs are a subclass of \textit{quadratic programs} (\textit{QPs}) optimization problems that are still characterized by linear constraints and a \textit{convex quadratic cost} in the form
	\[ \frac 1 2 x^\top H x + g^\top x  \]
	with $H$ that's a semi-positive definite matrix.
	
	Numerical solvers are usually developed for QP problems, but they can be used also to solve least square programs (still "ad hoc" solvers might find the solution more efficiently). In general LSPs and QPs are \textit{convex optimization problems} that can be solved in low time with off-the-shelf softwares.
	
	\paragraph{Least square programs} LSPs are characterized by a cost function of the form
	\begin{equation} \label{eq:lspfunction}
		f(x) = \frac 12 \big\|Ax - b\big\|^2 = \frac 1 2 \big(Ax-b\big)^\top\big(Ax -b\big) = \frac 1 2 x^\top A^\top A x - b^\top A x + \frac 1 2 b^\top b 
	\end{equation}
	Calling the product $A^\top A$ as $H$ that by definition is positive definite, then the similarity of LSPs with QPs is clear.
	
	Since the problem is convex then there's only one stationary point $x^\star$ of $f$ that's also the global minimum; $x^\star$ can be computed by setting to zero the gradient of the cost $f$, i.e. solving
	\[ \nabla f = A^\top A x - A^\top b = 0 \]
	Assuming that $A^\top A$ is invertible the explicit solution of the minimizing argument is
	\begin{equation*} \tag{$\dagger$}
		x^\star = \big(A^\top A\big)^{-1} A^\top b
	\end{equation*}
	where $\big(A^\top A\big)^{-1} A^\top$ is the \textit{left pseudo-inverse} of $A$. If $A^\top A$ is not invertible but conversely $AA^\top$ is, then we can use the \textit{right pseudo-inverse} to obtain the solution
	\begin{equation*} \tag{$\ddagger$}
		x^\star = A^\top \big(AA^\top\big)^{-1} b
	\end{equation*}
	Plugging such optimal solution in (\ref{eq:lspfunction}) leads in fact to a zero (minimum) cost:
	\[ f(x^\star) =\big\| AA^\top\big(AA^\top\big)^{-1} b \big\|^2 = \|Ib-b\|^1 = 0 \]
	
	In general the solution of least square minimization problem is determined by means of the \textit{Moore-Penrose pseudo-inverse $A^\top$} as
	\begin{equation} \label{eq:lspsol}
		x^\star = \min_x \big\| Ax - b \big\|^2 = A^+ b
	\end{equation}
	where
	\begin{equation}
		A^+ = \begin{cases}
			A^\top\big(AA^\top\big)^{-1} & \textrm{if $A$ is a full-row rank matrix} \\
			\big(A^\top A\big)^{-1}A^\top & \textrm{if $A$ is a full-column rank matrix} 
		\end{cases}
	\end{equation}
	
	We observe now that both solutions ($\dagger$) and ($\ddagger$) have been obtained considering the respective definition of the Moore-Penrose pseudo-inverse based on the condition of the matrix $A$ (leading to the invertibility of $A^\top A$). Moreover, if $A$ is neither full-row and columns rank, still $A^+$ can be computed by means of the singular value decomposition, thus an optimal solution (\ref{eq:lspsol}) always exists for (\ref{eq:lspfunction}).
	
\subsection{Cartesian space control}
	We can use quadratic programs also to solve control problem in cartesian space. Recalling the desired cartesian acceleration $\ddot x^d = \ddot x^{ref} + K_p\big(x^{ref}-x\big) + K_d\big(\dot x^{ref} - \dot x\big)$ defined in (\ref{eq:cartesiancontroller}), we can formulate the control problem as th following optimization:
	\begin{align*}
		\min_{\tau, \ddot q} \quad & \frac12 \big\|\ddot x - \ddot x^d\|^2 \\
		\textrm{sub. to:} \quad & M\ddot q + h = \tau
	\end{align*}
	The main issue with this formulation is that the cost function lacks the dependence of the \textit{decision variables} that are just $\tau$ and $\ddot q$; in this case we have simply to add a new constraint relating $\ddot x$ with $\ddot q$, i.e. 
	\begin{equation}
	\begin{aligned}
		\min_{\tau, \ddot q} \quad & \frac12 \big\|\ddot x - \ddot x^d\|^2 \\
		\textrm{sub. to:} \quad & M\ddot q + h = \tau \\
		& \ddot x = J\ddot q + \dot J \dot q
	\end{aligned}
	\end{equation}
	To improve the numerical performance of the algorithm we can remove the lastly added constraint and explicitly substitute it in the cost function, reaching the following OCP:
	\begin{equation} \label{eq:qpcartesian}
		\begin{aligned}
			\min_{\tau, \ddot q} \quad & \frac12 \big\| J\ddot q + \dot J\dot q - \ddot x^d\|^2 \\
			\textrm{sub. to:} \quad & M\ddot q + h = \tau
		\end{aligned}
	\end{equation}
	
	Exploiting (\ref{eq:lspsol}) the optimal joint accelerations and torques are computed simply as
	\[ \ddot q^\star = J^+ \big(\ddot x^d - \dot J\dot q\big) \qquad \tau^\star = M \ddot q^\star + h \tag{$\triangle$} \]
	where in this case the coefficient $b$ is made by $\ddot x^d - \dot J \dot q$ (since all this quantities are known beforehand).
	
	\textbf{TODO: confrontare risultato con quello ottenuto in precedenza (pseudoinversa pesata)}
	
	
\subsection{Task space control}
	In this section we'll further generalize the concept of control in such a way that the target is not just a joint configuration or the end effector in cartesian coordinate, but a \textit{task}, a \textit{control objective} that the robot should achieve.
	
	Each task is usually described by an \textit{error function} $e(\cdot)$ that needs to be minimized; in all previous seen cases the error was just the difference between the current configuration and a reference one, i.e.
	\begin{equation}
		e(x,u,t) = y(x,u) - y^{ref}(t)
	\end{equation}
	where $x = (q,\dot q)$ are in this case the \textit{states} of the system and $u=\tau$ the inputs (using a more general notation).
	
	Since QP problems requires an error function $e$ that must be affine in the decision variable $\ddot q$, a transformation is required (such the one to solve the controls in cartesian space); minimizing directly $e$ is not possible as in general it depends only on $q$ and $\dot q$, not $\ddot q$ explicitly.\\
	To reach this goal we must impose the following two conditions on $e$ (or on it's derivative $\dot e,\ddot e$) for which:
	\begin{enumerate}
		\item $\lim_{t\rightarrow \infty} e(t) = 0$;
		\item the dynamics of $e$ is affine in the decision variables $\ddot q, u$.
	\end{enumerate}
	
	\paragraph{Velocity task function} Let's consider a case for which the error function depends just on the joint velocity (and eventually on time), so in the form $e(x,u,y) = e(\dot q, t) = y(\dot q) - y^{ref}(t)$; differentiating in time the error function provides
	\[ \dot e(\dot q, t) = \dot y - \dot y^{ref} = \pdiff y {\dot q} \diff {\dot q} t - \dot y^{ref} = J \ddot q - \dot y^{ref} \]
	This expression clearly satisfies the second requirement of being affine with respect to $\ddot q$; to ensure the second condition we can set $\dot e$ as proportional to the current error:
	\[ \dot e = -K_p e \]
	If $K_p$ is positive definite the linear dynamics is asymptotically stable, satisfying the second condition. The final cost function that can be used to solve this problem is so
	\begin{equation} 
	\begin{aligned} 
		J \ddot q - \dot y^{ref} & = - K_p e \qquad \textrm{with } K_p > 0 \\ 
		J\ddot q - \dot y^{ref} + K_p e & = 0
	\end{aligned}
	\end{equation}
	
	\paragraph{Position task function} Considering now a task depending just on the joint's position in the form $e(x,u,t) = e(q,t) = y(q) - y^{ref}(t)$, then an affine function in $\ddot q$ can be obtained considering 2 differentiation in time as follows:
	\[ \xrightarrow{\d/\d t} \qquad \dot e = J\dot q - \dot y^{ref} \qquad \xrightarrow{\d/\d t} \qquad \ddot e = J \ddot q + \dot J \dot q - \ddot y^{ref} \tag{$\circ$}  \]
	In this way the second requirement for $e$ is required. To study the first condition we need to reduce the dynamic to a first order exploiting the variable $z = (e,\dot e)$, and considering for this case a proportional-derivative controller the linear system boils down to
	\[ \dot z = \begin{pmatrix}
		\dot e \\ \ddot e
	\end{pmatrix} = \begin{bmatrix}
		0 & I \\ -K_p & - K_d
	\end{bmatrix} \begin{pmatrix}
		e \\ \dot e
	\end{pmatrix} = A z  \]
	In this case matrices $K_p,K_d > 0$ must be chosen in such a way that $\ddot e = -K_p e - K_d \dot e$ is asymptotically stable ($A$ musth be Hurwitz). Since now also the first condition is met, we can rewrite ($\circ$) as
	\begin{align*}
		J\ddot q + \dot J \dot q - \ddot y^{ref} & = - K_p e - K_d \dot e \\
		J\ddot q + \dot J \dot q + K_p e + K_d \dot e & = 0
	\end{align*}
	
	Linear theory suggests that such dynamic is exponentially stable, however in this case no constraints have been considered (but they can limit the actual stabilization performance).
	
	\paragraph{Input task function} The only way to build a task function $e(u, t)$ that depends just on the input torques $\tau = u$ is by ensuring that $e$ is actually affine in $u$ (that's a decision variable), i.e. must be of the form
	\[ e(u,t) = A(t) u - b(t) \]
	
	\paragraph{Task summary} As just presented we might have 3 main kind of task function, respectively:
	\begin{itemize}
		\item one that's affine in the input $\tau = u$;
		\item two that are non-linear functions of the states $x$ but for which an affine function of $\ddot q$ can be achieved by means of one or two differentiation in time for velocity and position tasks respectively.
	\end{itemize}
	In general a combination of multiple tasks can be collapsed to a single task exploiting an "augmented" state vector $z = (\ddot q, u)$ that determines the following affine function:
	\[ g(z) = \begin{bmatrix}
		A_x & A_u
	\end{bmatrix} \begin{pmatrix}
		\ddot q \\ u
	\end{pmatrix} - b = Az - b \]
	
	\paragraph{QP-based control} The \textit{task-space inverse dynamics} (\textit{TSID}), also referred as \textit{QP-based control}, solves optimization problems in the for
	\begin{equation}
	\begin{aligned}
		\min_{z =(\ddot q, \tau)} \quad & \big\|Az-b \big\|^2 \\
		\textrm{sub. to:} \quad & \begin{bmatrix}
			M & -I
		\end{bmatrix} z = -h \\ 
		& \textit{other constraints}
	\end{aligned}
	\end{equation}
	This is a generalization of the QP joint space control in (\ref{eq:qp}), choosing $A = \begin{bmatrix} I & 0 \end{bmatrix}$ and $b = \ddot q^d$, or the cartesian space control in (\ref{eq:qpcartesian}), choosing $A = \begin{bmatrix} J & 0 \end{bmatrix}$ and $b = \ddot x^d - \dot J \dot q$.
	
	\textbf{TODO: underactuated systems, rigid contacts, multi-task control}
	
 	
	
	